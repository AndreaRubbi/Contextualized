{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of Contextualized ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualized ML Enables High-Resolution Heterogeneity \n",
    "By sharing information between all contexts, contextualized learning is able to estimate heterogeneity at fine-grained resolution.\n",
    "Cluster or cohort-based models treat every partition independently, limiting heterogeneity to\n",
    "coarse-grained resolution where there are large enough cohorts for independent estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition \n",
    "In this examples we are interested in learning Bayesian Networks (BNs) which are context-specific; i.e., theparameters and/or structure of the BNs may vary according to context. In this problem,for each observation $X∈R^p$, we also observe contextual data $C∈R^m$. \n",
    "We can describe this as factorizing $P(X, C) = \\int_W{dW P(X|W)P(W|C)P(C)}$; where $P(X|W)=BN(X|W)$ is the distribution implied by BN structure W.\n",
    "As a practical biological application, we can view X as gene expression, W as a gene regulatory network, and C as patient covariates which contextualize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a few libraries\n",
    "import numpy as np # for linear algebra operations\n",
    "import pandas as pd # for data manipulation \n",
    "import networkx as nx # for drawing graphs\n",
    "import matplotlib.pyplot as plt # for drawing graphs\n",
    "from rich import print # style \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*UserWarning.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the contextualized library, define $n$ simulated samples with context $C$. Gene expression $X$ depends on the BN defined by $W$, and is simulated using the helper function <i>simulate_linear_sem</i>, which simulates samples from linear structural equation modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from contextualized import dev_dags\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/andre/OneDrive/Desktop/Nebula/Contextualized/')\n",
    "import contextualized\n",
    "\n",
    "simulate_linear_sem = contextualized.dags.graph_utils.simulate_linear_sem \n",
    "\n",
    "# number of samples\n",
    "n = 1000\n",
    "# C is the context\n",
    "C = np.linspace(1, 5, n).reshape((n, 1))\n",
    "# W is the adjacency matrix that defines the BN\n",
    "W = np.zeros((4, 4, n, 1)) # 4 genes and n adjacency matrices\n",
    "W[0, 1] = C - 2\n",
    "W[2, 1] = C**2\n",
    "W[3, 1] = C**3\n",
    "W[3, 2] = C\n",
    "W = np.squeeze(W)\n",
    "W = np.transpose(W, (2, 0, 1))\n",
    "# X is the gene expression\n",
    "X = np.zeros((n, 4))\n",
    "for i, w in enumerate(W):\n",
    "    x = simulate_linear_sem(w, 1, \"uniform\", noise_scale=0.1)[0]\n",
    "    X[i] = x\n",
    "\n",
    "print(C.shape, W.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from contextualized.easy import ContextualizedBayesianNetworks\n",
    "cbn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "cbn.fit(C, X, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we consider a constant $C$, we are indirectly defining a population model. We use this idea to compare the performance of contextualized against not-contextualized BNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const_C = np.ones((n, 1))\n",
    "print(const_C.shape, W.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "bn.fit(const_C, X, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4e+04</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mContextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m1.4e+04\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Not-Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.7e+04</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mNot-Contextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m5.7e+04\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can measure Mean-Squared Error to measure likelihood of X under predicted networks.\n",
    "c_mses = np.mean(cbn.measure_mses(C, X))\n",
    "mses = np.mean(bn.measure_mses(C, X))\n",
    "print(f'[bold green]Contextualized Model\\'s Mean Squared Error = [bold cyan]{c_mses:.2}')\n",
    "print(f'[bold green]Not-Contextualized Model\\'s Mean Squared Error = [bold cyan]{mses:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Comparison of inferred BNs</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Comparison of inferred BNs\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict and visualize network\n",
    "predicted_contextualized_networks = cbn.predict_networks(C)\n",
    "predicted_networks = bn.predict_networks(C)\n",
    "print(f'[bold green] Comparison of inferred BNs')\n",
    "f, axarr = plt.subplots(1, 3)\n",
    "axarr[0].imshow(predicted_contextualized_networks[0])\n",
    "axarr[1].imshow(W[0])\n",
    "axarr[2].imshow(predicted_networks[0])\n",
    "axarr[0].set_title(\"Predicted CBN\")\n",
    "axarr[1].set_title(\"Ground-Truth Network\")\n",
    "axarr[2].set_title(\"Predicted BN\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualized ML Enables Analysis of Latent Processes\n",
    "Cluster or cohort models are inferred by partitioning data into groups, assumed to be iid, and estimating models for each groups. This\n",
    "is only likely to be satisfied when contexts are discrete, low-dimensional, and every context-specific\n",
    "population is well observed. In real life, contexts are often continuous, high dimensional, and sparsely\n",
    "observed. When cluster or cohort approaches are applied in these circumstances, downstream modeling tasks are distorted by mis-specification, where many non-id samples are funneled into a single model. Consequently, there are no theoretical guarantees in many real life circumstances about how\n",
    "well a cluster or cohort model can represent heterogeneous populations. Alternatively, contextualized\n",
    "learning provides a way to estimate latent, non-id models for all samples with minimal assumptions\n",
    "about the grouping or clustering of these samples, or the functional relationship between latent models and contexts. Samples can then be grouped on the basis of model parameters and distributional\n",
    "differences to produce clusters in the latent model space underlying each sample. Contextualized ML\n",
    "intuitively recovers latent structures underlying data generation in a way a priori clustering cannot. Allowing downstream models to determine the grouping of samples rather than upstream contexts replaces\n",
    "traditional cluster analysis with contextualized analysis clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example depicted above, let's suppose the context $C$ of the gene expression $X$ is defined by some covariates $Z$. <br>\n",
    "The context $C$ of each individual is modeled by $C = \\beta(Z) + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of samples\n",
    "n = 1000\n",
    "# Covariates Z\n",
    "Z = np.random.normal(-1, 1, (n, 5))\n",
    "# beta\n",
    "beta = np.random.normal(-1, 1, (5, 1))\n",
    "# C is the context\n",
    "C = np.matmul(Z, beta)\n",
    "# W is the adjacency matrix that defines the BN\n",
    "W = np.zeros((4, 4, n, 1)) # 4 genes and n adjacency matrices\n",
    "W[0, 1] = C - 2\n",
    "W[2, 1] = C**2\n",
    "W[3, 1] = C**3\n",
    "W[3, 2] = C\n",
    "W = np.squeeze(W)\n",
    "W = np.transpose(W, (2, 0, 1))\n",
    "# X is the gene expression\n",
    "X = np.zeros((n, 4))\n",
    "for i, w in enumerate(W):\n",
    "    x = simulate_linear_sem(w, 1, \"uniform\", noise_scale=0.1)[0]\n",
    "    X[i] = x\n",
    "\n",
    "print(C.shape, W.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "cbn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "cbn.fit(C, X, max_epochs=10)\n",
    "const_C = np.ones((n, 1))\n",
    "bn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "bn.fit(const_C, X, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.7e+07</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mContextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m6.7e+07\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Not-Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.9e+08</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mNot-Contextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m7.9e+08\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can measure Mean-Squared Error to measure likelihood of X under predicted networks.\n",
    "c_mses = np.mean(cbn.measure_mses(C, X))\n",
    "mses = np.mean(bn.measure_mses(C, X))\n",
    "print(f'[bold green]Contextualized Model\\'s Mean Squared Error = [bold cyan]{c_mses:.2}')\n",
    "print(f'[bold green]Not-Contextualized Model\\'s Mean Squared Error = [bold cyan]{mses:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualized ML Interpolates Between Observed Contexts \n",
    "By learning to translate contextual information into model parameters, contextualized models learn about the meta-distribution of\n",
    "contexts. As a result, contextualized models can adapt to contexts which were never observed\n",
    "in the training data by interpolating between observed contexts or extrapolating to new contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le's assume we observe a certain set of contexts in our initial population, how well does the contextualized model generalize to new/unobserved contexts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m2000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m2000\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m2000\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of samples\n",
    "n = 2000\n",
    "# C is the context\n",
    "# C in [1,2] & [5,6] for the initial population\n",
    "# C in [2,5] for the unobserved population\n",
    "C = np.concatenate([np.linspace(1, 2, n//4), np.linspace(5, 6, n//4), np.linspace(2, 5, n//2)]).reshape((n, 1))\n",
    "# W is the adjacency matrix that defines the BN\n",
    "W = np.zeros((4, 4, n, 1)) # 4 genes and n adjacency matrices\n",
    "W[0, 1] = C - 2\n",
    "W[2, 1] = C**2\n",
    "W[3, 1] = C**3\n",
    "W[3, 2] = C\n",
    "W = np.squeeze(W)\n",
    "W = np.transpose(W, (2, 0, 1))\n",
    "# X is the gene expression\n",
    "X = np.zeros((n, 4))\n",
    "for i, w in enumerate(W):\n",
    "    x = simulate_linear_sem(w, 1, \"uniform\", noise_scale=0.1)[0]\n",
    "    X[i] = x\n",
    "print(C.shape, W.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | encoder   | MLP       | 1.8 K \n",
      "1 | explainer | Explainer | 256   \n",
      "----------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "cbn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "cbn.fit(C[:n//2], X[:n//2], max_epochs=10)\n",
    "const_C = np.ones((n//2, 1))\n",
    "bn = ContextualizedBayesianNetworks(\n",
    "    encoder_type='mlp', num_archetypes=16,\n",
    "    n_bootstraps=2, archetype_dag_loss_type=\"DAGMA\", archetype_alpha=0.,\n",
    "    sample_specific_dag_loss_type=\"DAGMA\", sample_specific_alpha=1e-1,\n",
    "    learning_rate=1e-3)\n",
    "bn.fit(const_C, X[:n//2], max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.8e+04</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mContextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m3.8e+04\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Not-Contextualized Model's Mean Squared Error = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2e+05</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mNot-Contextualized Model's Mean Squared Error = \u001b[0m\u001b[1;36m2.2e+05\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can measure Mean-Squared Error to measure likelihood of X under predicted networks.\n",
    "c_mses = np.mean(cbn.measure_mses(C[n//2:], X[n//2:]))\n",
    "mses = np.mean(bn.measure_mses(C[n//2:], X[n//2:]))\n",
    "print(f'[bold green]Contextualized Model\\'s Mean Squared Error = [bold cyan]{c_mses:.2}')\n",
    "print(f'[bold green]Not-Contextualized Model\\'s Mean Squared Error = [bold cyan]{mses:.2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
